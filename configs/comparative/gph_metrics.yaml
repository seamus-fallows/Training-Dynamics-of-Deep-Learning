experiment:
  name: gph_comparative_metrics

shared:
  model:
    in_dim: 5
    out_dim: 5
    num_hidden: 3
    hidden_dim: 100
    gamma: 1.0
    model_seed: 0
  training:
    lr: 0.0001
    optimizer: SGD
    optimizer_params: null
    criterion: MSELoss
    batch_seed: 0
    track_train_loss: false

model_a: {}
model_b: {}

# A = GD (full batch), B = SGD (mini-batch)
training_a:
  batch_size: null
training_b:
  batch_size: 10

data:
  train_samples: 500
  test_samples: 500
  data_seed: 0
  online: false
  noise_std: 0.0
  params:
    matrix: diagonal
    scale: 10.0

max_steps: 10000
num_evaluations: 250

# Per-model metrics: GD (model_a) is deterministic, so we only track
# metrics for SGD (model_b). GD metrics come from a separate single-model sweep.
metrics_a: []
metrics:
  - layer_norms
  - gram_norms
  - balance_diffs
  - effective_weight_norm

comparative_metrics:
  - param_distance
  - layer_distances
  - frobenius_distance

callbacks_a: []
callbacks_b: []
